{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126040,"status":"ok","timestamp":1725519864856,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"0ppQeUvGwaAR","outputId":"b4e222c6-f79a-415f-e3cc-9a536ba09403"},"outputs":[],"source":["# !pip install tsgm"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":30086,"status":"ok","timestamp":1725519894932,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"aK-6tQbMp1sg"},"outputs":[],"source":["import tensorflow as tf\n","import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, LayerNormalization, Dense, Attention, MultiHeadAttention, Lambda\n","from tensorflow.keras.models import Model, Sequential\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from tensorflow.keras import backend as K\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# import tsgm"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13555,"status":"ok","timestamp":1725519908484,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"NHsvN4F9qWj4","outputId":"8f20d8be-5003-4b06-a1c7-6bd7d3c2cb8b"},"outputs":[],"source":["# !gdown --fuzzy https://drive.google.com/file/d/1F9uinZY-eG4x9dNsUOOtAAZMYq6p945U/view?usp=drive_link\n","# !unzip -qq \"ASL-Sensor-Dataglove-Dataset.zip\" -d glove_data\n","# !echo \"Unzip successfully\""]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1725519908485,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"xX-l2zuop1sh"},"outputs":[],"source":["class TimeSeriesDataset:\n","    def __init__(self, root_dir, feature_names=[]):\n","        self.data = self.load_data(root_dir, feature_names)\n","        self.merge_flex_sensors()\n","\n","    def load_data(self, root_dir, feature_names):\n","        data = []\n","\n","        for individual_dir in sorted(os.listdir(root_dir)):\n","            individual_path = os.path.join(root_dir, individual_dir)\n","            for class_dir in sorted(os.listdir(individual_path)):\n","                class_path = os.path.join(individual_path, class_dir)\n","                if os.path.isdir(class_path):\n","                    for file in glob.glob(os.path.join(class_path, \"*.csv\")):\n","                        df = pd.read_csv(file, usecols=feature_names)\n","                        class_name = os.path.splitext(os.path.basename(file))[0]\n","                        df[\"class\"] = class_name\n","                        data.append(df)\n","\n","\n","        # Concatenate all data frames into a single data frame\n","        data = pd.concat(data, ignore_index=True)\n","        return data\n","    \n","    def merge_flex_sensors(self):\n","        if 'flex_4' in self.data.columns and 'flex_5' in self.data.columns:\n","            # Define a small epsilon value to avoid division by zero\n","            epsilon = 1e-10\n","\n","            # Convert flex sensor values to conductance (1/R), handling zero values\n","            conductance_4 = 1 / (self.data['flex_4'] + epsilon)\n","            conductance_5 = 1 / (self.data['flex_5'] + epsilon)\n","            \n","            # Sum the conductances\n","            total_conductance = conductance_4 + conductance_5\n","            \n","            # Convert back to resistance, handling very large values\n","            self.data['flex_4'] = np.where(\n","                total_conductance > epsilon,\n","                1 / total_conductance,\n","                np.finfo(float).max  # Use maximum float value for near-zero conductance\n","            )\n","            \n","            # Drop original columns\n","            self.data = self.data.drop(columns=['flex_5'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":16265,"status":"ok","timestamp":1725519924739,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"_1mCno1dp1sh"},"outputs":[],"source":["root_dir = \"glove_data/\"\n","feature_names = [\n","    \"flex_1\", \"flex_2\", \"flex_3\", \"flex_4\",\n","    \"GYRx\", \"GYRy\", \"GYRz\"\n","]\n","\n","dataset = TimeSeriesDataset(root_dir, feature_names).data\n","# dataset = dataset.sort_values(by=[\"class\"])\n","\n","# filter_classes = [\"deaf\", \"fine\", \"good\", \"goodbye\", \"hello\"]\n","# dataset = dataset[dataset[\"class\"].isin(filter_classes)]\n","\n","x_data, y_data = dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values\n","\n","scaler = StandardScaler()\n","x_data = scaler.fit_transform(x_data)\n","\n","label_encoder = LabelEncoder()\n","y_data = label_encoder.fit_transform(y_data)\n","\n","timesteps = 150\n","n_features = 7\n","num_classes = len(np.unique(y_data))\n","\n","num_samples = len(y_data) // timesteps\n","\n","x_data = x_data[:num_samples * timesteps].reshape((num_samples, timesteps, n_features))\n","y_data = y_data[:num_samples * timesteps:timesteps]\n"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1725519924739,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"ZLd4VjO5K-7p"},"outputs":[],"source":["# aug_model = tsgm.models.augmentations.GaussianNoise()\n","# x_data_aug = aug_model.generate(x_data, n_samples=x_data.shape[0], variance=0.2)\n","\n","# x_data = np.concatenate((x_data, x_data_aug), axis=0)\n","# y_data = np.concatenate((y_data, y_data), axis=0)\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1725519924740,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"yQozsMv1yJMP","outputId":"5da34a12-6f05-4e0f-b429-bd5d55433cdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["(10000, 150, 7)\n","(10000,)\n"]}],"source":["print(x_data.shape)\n","print(y_data.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1725519924740,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"ij1_LtWpK7kE"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1725519924740,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"D1JBuYi5p1si"},"outputs":[],"source":["def positional_encoding(length, depth):\n","    depth = int(depth)\n","    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n","    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n","\n","    angle_rates = 1 / (10000**depths)                # (1, depth)\n","    angle_rads = positions * angle_rates             # (pos, depth)\n","\n","    pos_encoding = np.concatenate(\n","        [np.sin(angle_rads), np.cos(angle_rads)],\n","        axis=-1)\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","class AddPositionalEncoding(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def build(self, input_shape):\n","        _, seq_len, d_model = input_shape\n","        self.pos_encoding = positional_encoding(seq_len, d_model)\n","\n","    def call(self, inputs):\n","        # Ensure positional encoding has the same shape as the input\n","        return inputs + self.pos_encoding[:tf.shape(inputs)[1], :tf.shape(inputs)[2]]\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        return config\n","\n","def create_model(timesteps, n_features, num_classes):\n","    inputs = Input(shape=(timesteps, n_features))\n","\n","    x = Conv1D(filters=64, kernel_size=5, activation='relu')(inputs)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = LSTM(units=128, return_sequences=True)(x)\n","    x = LSTM(units=128, return_sequences=True)(x)\n","\n","    x = AddPositionalEncoding()(x)\n","\n","    # MultiHeadAttention layer\n","    attn_output = MultiHeadAttention(num_heads=4, key_dim=128)(x, x, x)\n","    x = LayerNormalization()(attn_output + x)\n","\n","    x = Dense(units=128, activation='relu')(x)\n","\n","    # Global Attention layer\n","    attn = Attention()([x, x])\n","    x = LayerNormalization()(attn + x)\n","\n","    # Global average pooling to reduce sequence dimension\n","    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n","\n","    outputs = Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51545,"status":"ok","timestamp":1725519976273,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"IWIToYW-p1si","outputId":"a2b25791-a65a-42ba-ff53-8b19d9cd9c03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_3 (InputLayer)        [(None, 150, 7)]             0         []                            \n","                                                                                                  \n"," conv1d_8 (Conv1D)           (None, 146, 64)              2304      ['input_3[0][0]']             \n","                                                                                                  \n"," max_pooling1d_8 (MaxPoolin  (None, 73, 64)               0         ['conv1d_8[0][0]']            \n"," g1D)                                                                                             \n","                                                                                                  \n"," conv1d_9 (Conv1D)           (None, 69, 64)               20544     ['max_pooling1d_8[0][0]']     \n","                                                                                                  \n"," max_pooling1d_9 (MaxPoolin  (None, 34, 64)               0         ['conv1d_9[0][0]']            \n"," g1D)                                                                                             \n","                                                                                                  \n"," conv1d_10 (Conv1D)          (None, 30, 64)               20544     ['max_pooling1d_9[0][0]']     \n","                                                                                                  \n"," max_pooling1d_10 (MaxPooli  (None, 15, 64)               0         ['conv1d_10[0][0]']           \n"," ng1D)                                                                                            \n","                                                                                                  \n"," conv1d_11 (Conv1D)          (None, 11, 64)               20544     ['max_pooling1d_10[0][0]']    \n","                                                                                                  \n"," max_pooling1d_11 (MaxPooli  (None, 5, 64)                0         ['conv1d_11[0][0]']           \n"," ng1D)                                                                                            \n","                                                                                                  \n"," lstm_4 (LSTM)               (None, 5, 128)               98816     ['max_pooling1d_11[0][0]']    \n","                                                                                                  \n"," lstm_5 (LSTM)               (None, 5, 128)               131584    ['lstm_4[0][0]']              \n","                                                                                                  \n"," add_positional_encoding_2   (None, 5, 128)               0         ['lstm_5[0][0]']              \n"," (AddPositionalEncoding)                                                                          \n","                                                                                                  \n"," multi_head_attention_2 (Mu  (None, 5, 128)               263808    ['add_positional_encoding_2[0]\n"," ltiHeadAttention)                                                  [0]',                         \n","                                                                     'add_positional_encoding_2[0]\n","                                                                    [0]',                         \n","                                                                     'add_positional_encoding_2[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," tf.__operators__.add_4 (TF  (None, 5, 128)               0         ['multi_head_attention_2[0][0]\n"," OpLambda)                                                          ',                            \n","                                                                     'add_positional_encoding_2[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," layer_normalization_4 (Lay  (None, 5, 128)               256       ['tf.__operators__.add_4[0][0]\n"," erNormalization)                                                   ']                            \n","                                                                                                  \n"," dense_4 (Dense)             (None, 5, 128)               16512     ['layer_normalization_4[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," attention_2 (Attention)     (None, 5, 128)               0         ['dense_4[0][0]',             \n","                                                                     'dense_4[0][0]']             \n","                                                                                                  \n"," tf.__operators__.add_5 (TF  (None, 5, 128)               0         ['attention_2[0][0]',         \n"," OpLambda)                                                           'dense_4[0][0]']             \n","                                                                                                  \n"," layer_normalization_5 (Lay  (None, 5, 128)               256       ['tf.__operators__.add_5[0][0]\n"," erNormalization)                                                   ']                            \n","                                                                                                  \n"," global_average_pooling1d_2  (None, 128)                  0         ['layer_normalization_5[0][0]'\n","  (GlobalAveragePooling1D)                                          ]                             \n","                                                                                                  \n"," dense_5 (Dense)             (None, 40)                   5160      ['global_average_pooling1d_2[0\n","                                                                    ][0]']                        \n","                                                                                                  \n","==================================================================================================\n","Total params: 580328 (2.21 MB)\n","Trainable params: 580328 (2.21 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","125/125 [==============================] - 10s 44ms/step - loss: 1.9275 - accuracy: 0.4004 - val_loss: 1.0052 - val_accuracy: 0.6130\n","Epoch 2/30\n","125/125 [==============================] - 5s 37ms/step - loss: 0.9124 - accuracy: 0.6340 - val_loss: 0.9318 - val_accuracy: 0.6435\n","Epoch 3/30\n","125/125 [==============================] - 5s 37ms/step - loss: 0.7922 - accuracy: 0.6766 - val_loss: 0.9916 - val_accuracy: 0.5960\n","Epoch 4/30\n","125/125 [==============================] - 5s 38ms/step - loss: 0.7375 - accuracy: 0.6929 - val_loss: 0.9225 - val_accuracy: 0.6345\n","Epoch 5/30\n","125/125 [==============================] - 5s 39ms/step - loss: 0.7012 - accuracy: 0.7078 - val_loss: 0.9994 - val_accuracy: 0.6150\n","Epoch 6/30\n","125/125 [==============================] - 5s 39ms/step - loss: 0.6754 - accuracy: 0.7096 - val_loss: 0.8807 - val_accuracy: 0.6560\n","Epoch 7/30\n","125/125 [==============================] - 5s 39ms/step - loss: 0.6367 - accuracy: 0.7280 - val_loss: 1.1346 - val_accuracy: 0.5955\n","Epoch 8/30\n","125/125 [==============================] - 5s 40ms/step - loss: 0.6060 - accuracy: 0.7420 - val_loss: 0.9598 - val_accuracy: 0.6390\n","Epoch 9/30\n","125/125 [==============================] - 5s 39ms/step - loss: 0.5703 - accuracy: 0.7596 - val_loss: 0.9690 - val_accuracy: 0.6415\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1e0a8b80b10>"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["model = create_model(timesteps, n_features, num_classes)\n","model.summary()\n","\n","# checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model_weights.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_data, y_data, epochs=30, batch_size=64, validation_split = 0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["if not os.path.exists(\"model\"):\n","    os.makedirs(\"model\")\n","model.save(\"models/SADeepConvLSTM_TransferLearning.h5\")"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2202,"status":"ok","timestamp":1725519978462,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"CIlZKH1arDQs","outputId":"6d9aadf7-fc43-4f59-cd7d-1052162dbdfb"},"outputs":[],"source":["# y_pred = model.predict(x_test)\n","# y_pred = np.argmax(y_pred, axis=1)\n","# accuracy = accuracy_score(y_test, y_pred)\n","# print(\"Accuracy:\", accuracy)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":5291,"status":"ok","timestamp":1725519983751,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"xAqjjKJfsAxl","outputId":"e7f2ec60-fdfb-4bdc-b785-80fd5d133c4d"},"outputs":[],"source":["# cm = confusion_matrix(y_test, y_pred)\n","# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label_encoder.classes_))\n","# disp.plot(cmap=plt.cm.Blues)\n","# plt.show()"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1725519983751,"user":{"displayName":"Hòa Nguyễn","userId":"08524944918431446312"},"user_tz":-420},"id":"HXyJfjuBN6Rs","outputId":"c12355fa-e3e4-45e2-ec77-632d419801ef"},"outputs":[],"source":["# print(classification_report(y_test, y_pred))"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/orangethefish/ASL_Glove/blob/main/self_attention_lstm.ipynb","timestamp":1721873593286}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
