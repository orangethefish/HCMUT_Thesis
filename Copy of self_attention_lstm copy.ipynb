{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126040,
     "status": "ok",
     "timestamp": 1725519864856,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "0ppQeUvGwaAR",
    "outputId": "b4e222c6-f79a-415f-e3cc-9a536ba09403"
   },
   "outputs": [],
   "source": [
    "# !pip install tsgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 30086,
     "status": "ok",
     "timestamp": 1725519894932,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "aK-6tQbMp1sg"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, LayerNormalization, Dense, Attention, MultiHeadAttention, Lambda\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "# import seaborn as sns\n",
    "# import tsgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13555,
     "status": "ok",
     "timestamp": 1725519908484,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "NHsvN4F9qWj4",
    "outputId": "8f20d8be-5003-4b06-a1c7-6bd7d3c2cb8b"
   },
   "outputs": [],
   "source": [
    "# !gdown --fuzzy https://drive.google.com/file/d/1F9uinZY-eG4x9dNsUOOtAAZMYq6p945U/view?usp=drive_link\n",
    "# !unzip -qq \"ASL-Sensor-Dataglove-Dataset.zip\" -d glove_data\n",
    "# !echo \"Unzip successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1725519908485,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "xX-l2zuop1sh"
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset:\n",
    "    def __init__(self, root_dir, feature_names=[]):\n",
    "        self.data = self.load_data(root_dir, feature_names)\n",
    "        self.merge_flex_sensors()\n",
    "\n",
    "    def load_data(self, root_dir, feature_names):\n",
    "        data = []\n",
    "\n",
    "        for individual_dir in sorted(os.listdir(root_dir)):\n",
    "            individual_path = os.path.join(root_dir, individual_dir)\n",
    "            for class_dir in sorted(os.listdir(individual_path)):\n",
    "                class_path = os.path.join(individual_path, class_dir)\n",
    "                if os.path.isdir(class_path):\n",
    "                    for file in glob.glob(os.path.join(class_path, \"*.csv\")):\n",
    "                        df = pd.read_csv(file, usecols=feature_names)\n",
    "                        class_name = os.path.splitext(os.path.basename(file))[0]\n",
    "                        df[\"class\"] = class_name\n",
    "                        data.append(df)\n",
    "\n",
    "\n",
    "        # Concatenate all data frames into a single data frame\n",
    "        data = pd.concat(data, ignore_index=True)\n",
    "        return data\n",
    "    \n",
    "    def merge_flex_sensors(self):\n",
    "        if 'flex_1' in self.data.columns and 'flex_2' in self.data.columns:\n",
    "            # Define a small epsilon value to avoid division by zero\n",
    "            epsilon = 1e-10\n",
    "\n",
    "            # Convert flex sensor values to conductance (1/R), handling zero values\n",
    "            conductance_4 = 1 / (self.data['flex_1'] + epsilon)\n",
    "            conductance_5 = 1 / (self.data['flex_2'] + epsilon)\n",
    "            \n",
    "            # Sum the conductances\n",
    "            total_conductance = conductance_4 + conductance_5\n",
    "            \n",
    "            # Convert back to resistance, handling very large values\n",
    "            self.data['flex_1'] = np.where(\n",
    "                total_conductance > epsilon,\n",
    "                1 / total_conductance,\n",
    "                np.finfo(float).max  # Use maximum float value for near-zero conductance\n",
    "            )\n",
    "            \n",
    "            # Drop original columns\n",
    "            self.data = self.data.drop(columns=['flex_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 16265,
     "status": "ok",
     "timestamp": 1725519924739,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "_1mCno1dp1sh"
   },
   "outputs": [],
   "source": [
    "root_dir = \"glove_data/\"\n",
    "feature_names = [\n",
    "    \"flex_1\", \"flex_3\", \"flex_4\", \"flex_5\",\n",
    "    \"GYRx\", \"GYRy\", \"GYRz\"\n",
    "]\n",
    "\n",
    "dataset = TimeSeriesDataset(root_dir, feature_names).data\n",
    "# dataset = dataset.sort_values(by=[\"class\"])\n",
    "\n",
    "# filter_classes = [\"deaf\", \"fine\", \"good\", \"goodbye\", \"hello\"]\n",
    "# dataset = dataset[dataset[\"class\"].isin(filter_classes)]\n",
    "\n",
    "x_data, y_data = dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# x_data = scaler.fit_transform(x_data)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_data = label_encoder.fit_transform(y_data)\n",
    "\n",
    "timesteps = 150\n",
    "n_features = 7\n",
    "num_classes = len(np.unique(y_data))\n",
    "\n",
    "num_samples = len(y_data) // timesteps\n",
    "\n",
    "x_data = x_data[:num_samples * timesteps].reshape((num_samples, timesteps, n_features))\n",
    "y_data = y_data[:num_samples * timesteps:timesteps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 240, 7)\n"
     ]
    }
   ],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "# Define original and new timesteps\n",
    "old_timesteps = np.arange(150)\n",
    "new_timesteps = np.linspace(0, 149, 240)  # New time steps from 0 to 149, but 240 steps in between\n",
    "\n",
    "# Initialize an empty array for the upsampled data\n",
    "upsampled_data = np.zeros((x_data.shape[0], 240, x_data.shape[2]))\n",
    "\n",
    "# Interpolate along the time dimension for each sample and each feature\n",
    "for i in range(x_data.shape[0]):  # Iterate over each sample\n",
    "    for j in range(x_data.shape[2]):  # Iterate over each feature\n",
    "        f = interpolate.interp1d(old_timesteps, x_data[i, :, j], kind='linear')\n",
    "        upsampled_data[i, :, j] = f(new_timesteps)\n",
    "\n",
    "print(upsampled_data.shape)  # Should print (10000, 240, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |       0 |       1 |       2 |       3 |          4 |          5 |         6 |\n",
      "|---:|--------:|--------:|--------:|--------:|-----------:|-----------:|----------:|\n",
      "|  0 | 20      | 72      | 77      | 58      | -0.068702  | -0.015267  | 0.015267  |\n",
      "|  1 | 20      | 70.7531 | 76.3766 | 58      | -0.0734613 | -0.015267  | 0.0200263 |\n",
      "|  2 | 20      | 70.7406 | 75.7531 | 58.4937 | -0.076336  | -0.0171515 | 0.022901  |\n",
      "|  3 | 20      | 72.6109 | 75.1297 | 59.7406 | -0.076336  | -0.0219108 | 0.022901  |\n",
      "|  4 | 19.5063 | 73      | 76.9749 | 59.0126 | -0.076336  | -0.022901  | 0.022901  |\n"
     ]
    }
   ],
   "source": [
    "temp = pd.DataFrame(upsampled_data.reshape(-1, n_features))\n",
    "print(temp.head().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = upsampled_data\n",
    "timesteps = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1725519924739,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "ZLd4VjO5K-7p"
   },
   "outputs": [],
   "source": [
    "# aug_model = tsgm.models.augmentations.GaussianNoise()\n",
    "# x_data_aug = aug_model.generate(x_data, n_samples=x_data.shape[0], variance=0.2)\n",
    "\n",
    "# x_data = np.concatenate((x_data, x_data_aug), axis=0)\n",
    "# y_data = np.concatenate((y_data, y_data), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1725519924740,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "yQozsMv1yJMP",
    "outputId": "5da34a12-6f05-4e0f-b429-bd5d55433cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 240, 7)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1725519924740,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "ij1_LtWpK7kE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1725519924740,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "D1JBuYi5p1si"
   },
   "outputs": [],
   "source": [
    "# def positional_encoding(length, depth):\n",
    "#     depth = int(depth)\n",
    "#     positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "#     depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "#     angle_rates = 1 / (10000**depths)                # (1, depth)\n",
    "#     angle_rads = positions * angle_rates             # (pos, depth)\n",
    "\n",
    "#     pos_encoding = np.concatenate(\n",
    "#         [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "#         axis=-1)\n",
    "\n",
    "#     return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "# class AddPositionalEncoding(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         _, seq_len, d_model = input_shape\n",
    "#         self.pos_encoding = positional_encoding(seq_len, d_model)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # Ensure positional encoding has the same shape as the input\n",
    "#         return inputs + self.pos_encoding[:tf.shape(inputs)[1], :tf.shape(inputs)[2]]\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return input_shape\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = super().get_config()\n",
    "#         return config\n",
    "\n",
    "# def create_model(timesteps, n_features, num_classes):\n",
    "#     inputs = Input(shape=(timesteps, n_features))\n",
    "\n",
    "#     x = Conv1D(filters=64, kernel_size=5, activation='relu')(inputs)\n",
    "#     x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     x = Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n",
    "#     x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     x = Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n",
    "#     x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     x = Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n",
    "#     x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     x = LSTM(units=128, return_sequences=True)(x)\n",
    "#     x = LSTM(units=128, return_sequences=True)(x)\n",
    "\n",
    "#     x = AddPositionalEncoding()(x)\n",
    "\n",
    "#     # MultiHeadAttention layer\n",
    "#     attn_output = MultiHeadAttention(num_heads=4, key_dim=128)(x, x, x)\n",
    "#     x = LayerNormalization()(attn_output + x)\n",
    "\n",
    "#     x = Dense(units=128, activation='relu')(x)\n",
    "\n",
    "#     # Global Attention layer\n",
    "#     attn = Attention()([x, x])\n",
    "#     x = LayerNormalization()(attn + x)\n",
    "\n",
    "#     # Global average pooling to reduce sequence dimension\n",
    "#     x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "#     outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "#     return model\n",
    "\n",
    "def create_model(timesteps, features, num_classes, name = \"original_model\"):\n",
    "    # define model\n",
    "    model = Sequential(name=name)\n",
    "    model.add(LSTM(units = 128, input_shape = (timesteps, features)))\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51545,
     "status": "ok",
     "timestamp": 1725519976273,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "IWIToYW-p1si",
    "outputId": "a2b25791-a65a-42ba-ff53-8b19d9cd9c03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"original_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"original_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m2,600\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,488</span> (314.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,488\u001b[0m (314.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,488</span> (314.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,488\u001b[0m (314.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 155ms/step - accuracy: 0.1097 - loss: 3.4050 - val_accuracy: 0.1960 - val_loss: 2.5437\n",
      "Epoch 2/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 155ms/step - accuracy: 0.2678 - loss: 2.2539 - val_accuracy: 0.2495 - val_loss: 2.2310\n",
      "Epoch 3/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - accuracy: 0.3195 - loss: 1.9669 - val_accuracy: 0.2815 - val_loss: 2.0829\n",
      "Epoch 4/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 151ms/step - accuracy: 0.3547 - loss: 1.8274 - val_accuracy: 0.2985 - val_loss: 2.0024\n",
      "Epoch 5/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 153ms/step - accuracy: 0.3617 - loss: 1.7581 - val_accuracy: 0.3030 - val_loss: 1.9402\n",
      "Epoch 6/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 151ms/step - accuracy: 0.3783 - loss: 1.7399 - val_accuracy: 0.3300 - val_loss: 1.9485\n",
      "Epoch 7/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 152ms/step - accuracy: 0.3881 - loss: 1.6988 - val_accuracy: 0.3350 - val_loss: 1.8994\n",
      "Epoch 8/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.4020 - loss: 1.6563 - val_accuracy: 0.3170 - val_loss: 1.9414\n",
      "Epoch 9/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 152ms/step - accuracy: 0.4098 - loss: 1.6242 - val_accuracy: 0.3200 - val_loss: 1.9168\n",
      "Epoch 10/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 152ms/step - accuracy: 0.4229 - loss: 1.6138 - val_accuracy: 0.3510 - val_loss: 1.9465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c07816ced0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(timesteps, n_features, num_classes)\n",
    "model.summary()\n",
    "\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model_weights.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_data, y_data, epochs=30, batch_size=64, validation_split = 0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"model\"):\n",
    "    os.makedirs(\"model\")\n",
    "model.save(\"model/LSTM_TransferLearning.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2202,
     "status": "ok",
     "timestamp": 1725519978462,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "CIlZKH1arDQs",
    "outputId": "6d9aadf7-fc43-4f59-cd7d-1052162dbdfb"
   },
   "outputs": [],
   "source": [
    "# y_pred = model.predict(x_test)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 5291,
     "status": "ok",
     "timestamp": 1725519983751,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "xAqjjKJfsAxl",
    "outputId": "e7f2ec60-fdfb-4bdc-b785-80fd5d133c4d"
   },
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label_encoder.classes_))\n",
    "# disp.plot(cmap=plt.cm.Blues)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1725519983751,
     "user": {
      "displayName": "Hòa Nguyễn",
      "userId": "08524944918431446312"
     },
     "user_tz": -420
    },
    "id": "HXyJfjuBN6Rs",
    "outputId": "c12355fa-e3e4-45e2-ec77-632d419801ef"
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/orangethefish/ASL_Glove/blob/main/self_attention_lstm.ipynb",
     "timestamp": 1721873593286
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
